{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e65bb84",
   "metadata": {},
   "source": [
    "# Eesti tarbimiskõverate 7-päevased protsentprofiilid\n",
    "\n",
    "**Eesmärk.** Luua järgmise 7 päeva tunniprofiilid protsentides (sum=100) kasutades ajalooliselt temperatuurilt sarnaseid päevi ning päevatüüpe (workday/saturday/sunday/holiday)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28cfa061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT = C:\\Users\\tarmo\\OneDrive\\Dokumendid\\GIT Andmetarkus\\portfolio\\Electricity-Consumption-Forecast\n",
      "OUTPUT_DIR   = C:\\Users\\tarmo\\OneDrive\\Dokumendid\\GIT Andmetarkus\\portfolio\\Electricity-Consumption-Forecast\\output\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Config & imports ---\n",
    "from pathlib import Path\n",
    "import sys, importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "PROJECT_ROOT = Path(\".\").resolve()\n",
    "LOCAL_TZ = \"Europe/Tallinn\"\n",
    "MIN_MATCHES = 10\n",
    "\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"output\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FORECAST_CSV = OUTPUT_DIR / \"forecast_profiles_next7d.csv\"\n",
    "\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
    "print(\"OUTPUT_DIR   =\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30901b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[warn] holidays library missing or failed; set hourly is_holiday=False. Install: pip install holidays\n",
      "\n",
      "=== Data Quality Report (hourly) ===\n",
      "Total rows: 17543\n",
      "sum_cons_time present: 17543 | missing: 0\n",
      "sum_el_hourly_value present: 17543 | missing: 0\n",
      "Duplicate timestamps: 0\n",
      "Date range: 2023-09-17 07:00:00+00:00 … 2025-09-17 06:00:00+00:00\n",
      "Imputed (mean of neighbors): 1\n",
      "Remaining missing after imputation: 0\n",
      "[warn] holidays library missing or failed; set daily is_holiday=False. Install: pip install holidays\n",
      "\n",
      "=== Hourly preview ===\n",
      "              sum_cons_time  sum_el_hourly_value  imputed weekday  is_weekend  \\\n",
      "0 2023-09-17 07:00:00+00:00                609.6    False  Sunday        True   \n",
      "1 2023-09-17 08:00:00+00:00                680.9    False  Sunday        True   \n",
      "2 2023-09-17 09:00:00+00:00                805.5    False  Sunday        True   \n",
      "3 2023-09-17 10:00:00+00:00                817.8    False  Sunday        True   \n",
      "4 2023-09-17 11:00:00+00:00                838.8    False  Sunday        True   \n",
      "\n",
      "   is_holiday  \n",
      "0       False  \n",
      "1       False  \n",
      "2       False  \n",
      "3       False  \n",
      "4       False  \n",
      "\n",
      "=== Daily preview ===\n",
      "  sum_cons_date  sum_el_daily_value    weekday  is_weekend  is_holiday\n",
      "0    2023-09-17             13065.6     Sunday        True       False\n",
      "1    2023-09-18             18073.3     Monday       False       False\n",
      "2    2023-09-19             20060.0    Tuesday       False       False\n",
      "3    2023-09-20             21285.4  Wednesday       False       False\n",
      "4    2023-09-21             20443.7   Thursday       False       False\n",
      "\n",
      "=== Column dtypes: sum_hourly_el_consumption ===\n",
      "sum_cons_time          datetime64[ns, UTC]\n",
      "sum_el_hourly_value                float64\n",
      "imputed                               bool\n",
      "weekday                             object\n",
      "is_weekend                            bool\n",
      "is_holiday                            bool\n",
      "dtype: object\n",
      "\n",
      "=== Column dtypes: sum_daily_el_consumption ===\n",
      "sum_cons_date          object\n",
      "sum_el_daily_value    float64\n",
      "weekday                object\n",
      "is_weekend               bool\n",
      "is_holiday               bool\n",
      "dtype: object\n",
      "\n",
      "=== .info() (hourly) ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17543 entries, 0 to 17542\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype              \n",
      "---  ------               --------------  -----              \n",
      " 0   sum_cons_time        17543 non-null  datetime64[ns, UTC]\n",
      " 1   sum_el_hourly_value  17543 non-null  float64            \n",
      " 2   imputed              17543 non-null  bool               \n",
      " 3   weekday              17543 non-null  object             \n",
      " 4   is_weekend           17543 non-null  bool               \n",
      " 5   is_holiday           17543 non-null  bool               \n",
      "dtypes: bool(3), datetime64[ns, UTC](1), float64(1), object(1)\n",
      "memory usage: 462.7+ KB\n",
      "\n",
      "=== .info() (daily) ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 732 entries, 0 to 731\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   sum_cons_date       732 non-null    object \n",
      " 1   sum_el_daily_value  732 non-null    float64\n",
      " 2   weekday             732 non-null    object \n",
      " 3   is_weekend          732 non-null    bool   \n",
      " 4   is_holiday          732 non-null    bool   \n",
      "dtypes: bool(2), float64(1), object(2)\n",
      "memory usage: 18.7+ KB\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'temp'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m sys.path.append(\u001b[38;5;28mstr\u001b[39m(PROJECT_ROOT))\n\u001b[32m      4\u001b[39m ecw = importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33mel_consumption_weekday\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m tp  = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      8\u001b[39m     tf = importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33mtemp_forecast\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# optional 7d forecast\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tarmo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     86\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'temp'"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Import project modules (historical consumption & temperature) ---\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "ecw = importlib.import_module(\"el_consumption_weekday\")\n",
    "tp  = importlib.import_module(\"temp\")\n",
    "\n",
    "try:\n",
    "    tf = importlib.import_module(\"temp_forecast\")  # optional 7d forecast\n",
    "    HAS_TEMP_FORECAST = True\n",
    "except Exception:\n",
    "    tf = None\n",
    "    HAS_TEMP_FORECAST = False\n",
    "\n",
    "hourly_df = ecw.sum_hourly_el_consumption.copy()\n",
    "daily_df  = ecw.sum_daily_el_consumption.copy()\n",
    "temp_df   = tp.avg_day_temp.copy()\n",
    "\n",
    "hourly_df.head(3), daily_df.head(3), temp_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf3adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_local</th>\n",
       "      <th>daytype</th>\n",
       "      <th>temp_round</th>\n",
       "      <th>hour</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-09-18</td>\n",
       "      <td>sunday</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3.712008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-09-18</td>\n",
       "      <td>sunday</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3.576925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-09-18</td>\n",
       "      <td>sunday</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3.528760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    date_local daytype  temp_round  hour   percent\n",
       "15  2023-09-18  sunday          12     0  3.712008\n",
       "16  2023-09-18  sunday          12     1  3.576925\n",
       "17  2023-09-18  sunday          12     2  3.528760"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- Build historical daily percent profiles ---\n",
    "hourly = hourly_df.copy()\n",
    "hourly['sum_cons_time'] = pd.to_datetime(hourly['sum_cons_time'], utc=True, errors='coerce')\n",
    "hourly = hourly.dropna(subset=['sum_cons_time']).sort_values('sum_cons_time')\n",
    "hourly['time_local'] = hourly['sum_cons_time'].dt.tz_convert(LOCAL_TZ)\n",
    "hourly['date_local'] = hourly['time_local'].dt.date\n",
    "hourly['hour_local'] = hourly['time_local'].dt.hour\n",
    "\n",
    "def daytype_from_row(weekday_name, is_weekend, is_holiday):\n",
    "    if bool(is_holiday): return 'holiday'\n",
    "    if bool(is_weekend):\n",
    "        if weekday_name == 'Saturday': return 'saturday'\n",
    "        if weekday_name == 'Sunday':   return 'sunday'\n",
    "        return 'weekend'\n",
    "    return 'workday'\n",
    "\n",
    "hourly['daytype'] = [\n",
    "    daytype_from_row(w, iw, ih)\n",
    "    for w, iw, ih in zip(hourly.get('weekday', pd.Series(['']*len(hourly))), \n",
    "                         hourly.get('is_weekend', pd.Series([False]*len(hourly))), \n",
    "                         hourly.get('is_holiday', pd.Series([False]*len(hourly))))]\n",
    "\n",
    "daily_hourly = (hourly.groupby(['date_local','hour_local'], as_index=False)['sum_el_hourly_value']\n",
    "                .sum(min_count=1).rename(columns={'sum_el_hourly_value':'consumption_hour'}))\n",
    "daily_tot = (daily_hourly.groupby('date_local', as_index=False)['consumption_hour']\n",
    "             .sum(min_count=1).rename(columns={'consumption_hour':'consumption_day'}))\n",
    "profiles = daily_hourly.merge(daily_tot, on='date_local', how='left')\n",
    "profiles['percent'] = np.where(profiles['consumption_day']>0,\n",
    "                               profiles['consumption_hour']/profiles['consumption_day']*100.0, np.nan)\n",
    "\n",
    "daytypes = (hourly.groupby('date_local', as_index=False).agg({'daytype':'first'}))\n",
    "profiles = profiles.merge(daytypes, on='date_local', how='left')\n",
    "\n",
    "temp_df2 = temp_df.copy()\n",
    "temp_df2['avg_day_temp_date'] = pd.to_datetime(temp_df2['avg_day_temp_date']).dt.date\n",
    "temp_df2['temp_c'] = pd.to_numeric(temp_df2['hour_day_value'], errors='coerce')\n",
    "temp_df2 = temp_df2[['avg_day_temp_date','temp_c']].dropna()\n",
    "\n",
    "profiles = profiles.merge(temp_df2, left_on='date_local', right_on='avg_day_temp_date', how='left')\n",
    "profiles['temp_round'] = profiles['temp_c'].round().astype('Int64')\n",
    "profiles = profiles.dropna(subset=['percent','temp_round'])\n",
    "\n",
    "# Helper base (only full 24h days)\n",
    "base = (profiles[['date_local','daytype','temp_round','hour_local','percent']]\n",
    "        .rename(columns={'hour_local':'hour'}))\n",
    "counts = base.groupby('date_local')['hour'].count()\n",
    "full_days = counts[counts>=24].index\n",
    "base = base[base['date_local'].isin(full_days)].copy()\n",
    "\n",
    "base.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d974191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] temp_forecast.py puudub või struktuur tundmatu. Täida 'temp_c' käsitsi (°C).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp_c</th>\n",
       "      <th>daytype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-09-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-09-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  temp_c   daytype\n",
       "0  2025-09-18     NaN   workday\n",
       "1  2025-09-19     NaN   workday\n",
       "2  2025-09-20     NaN  saturday\n",
       "3  2025-09-21     NaN    sunday\n",
       "4  2025-09-22     NaN   workday\n",
       "5  2025-09-23     NaN   workday\n",
       "6  2025-09-24     NaN   workday"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- Get next 7 days forecast temperatures ---\n",
    "def get_next7d_forecast():\n",
    "    if tf is not None:\n",
    "        import pandas as _pd\n",
    "        for name in dir(tf):\n",
    "            obj = getattr(tf, name)\n",
    "            if isinstance(obj, _pd.DataFrame):\n",
    "                cols = [c.lower() for c in obj.columns]\n",
    "                if any('date' in c for c in cols) and any(('temp' in c) or ('tavg' in c) for c in cols):\n",
    "                    fc = obj.copy()\n",
    "                    cols_map = {c.lower(): c for c in fc.columns}\n",
    "                    date_col = next((c for c in fc.columns if 'date' in c.lower()), None)\n",
    "                    temp_col = next((c for c in fc.columns if ('temp' in c.lower()) or ('tavg' in c.lower())), None)\n",
    "                    if date_col and temp_col:\n",
    "                        out = fc[[date_col, temp_col]].copy()\n",
    "                        out.columns = ['date','temp_c']\n",
    "                        out['date'] = pd.to_datetime(out['date']).dt.date\n",
    "                        out['temp_c'] = pd.to_numeric(out['temp_c'], errors='coerce')\n",
    "                        out = out.dropna().sort_values('date').head(7)\n",
    "                        if not out.empty:\n",
    "                            return out\n",
    "    # fallback: skeleton for manual input\n",
    "    today_local = datetime.now(timezone.utc).astimezone().date()\n",
    "    dummy = pd.DataFrame({'date':[today_local + timedelta(days=i) for i in range(1,8)],\n",
    "                          'temp_c':[np.nan]*7})\n",
    "    print(\"[info] temp_forecast.py puudub või struktuur tundmatu. Täida 'temp_c' käsitsi (°C).\")\n",
    "    return dummy\n",
    "\n",
    "forecast7 = get_next7d_forecast()\n",
    "\n",
    "def infer_daytype_from_date(d):\n",
    "    wd = pd.Timestamp(d).dayofweek\n",
    "    return 'workday' if wd<=4 else ('saturday' if wd==5 else 'sunday')\n",
    "\n",
    "if 'daytype' not in forecast7.columns:\n",
    "    forecast7['daytype'] = [infer_daytype_from_date(d) for d in forecast7['date']]\n",
    "\n",
    "forecast7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e630daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Sampling rules & profile aggregation ---\n",
    "def select_sample_for_day(target_daytype, target_temp_c, base_df, min_matches=10):\n",
    "    import pandas as _pd\n",
    "    if _pd.isna(target_temp_c):\n",
    "        return _pd.DataFrame(columns=['date_local','hour','percent'])\n",
    "\n",
    "    T = int(round(float(target_temp_c)))\n",
    "    pool = base_df.copy()\n",
    "\n",
    "    if target_daytype == 'workday':\n",
    "        pool = pool[pool['daytype']=='workday']\n",
    "        pool_h = None; pool_wknd = None\n",
    "    elif target_daytype == 'saturday':\n",
    "        pool = pool[pool['daytype']=='saturday']\n",
    "        pool_h = None; pool_wknd = None\n",
    "    elif target_daytype == 'sunday':\n",
    "        pool = pool[pool['daytype']=='sunday']\n",
    "        pool_h = None; pool_wknd = None\n",
    "    elif target_daytype == 'holiday':\n",
    "        pool_h = pool[pool['daytype']=='holiday']\n",
    "        pool_wknd = pool[pool['daytype'].isin(['saturday','sunday'])]\n",
    "        pool = None\n",
    "    else:\n",
    "        pool_h = None; pool_wknd = None  # use all if unknown\n",
    "\n",
    "    def by_temp_range(df, T, d):\n",
    "        return df[df['temp_round'].between(T-d, T+d)] if df is not None else df\n",
    "\n",
    "    if target_daytype == 'holiday':\n",
    "        sel = by_temp_range(pool_h, T, 0)\n",
    "        d = 0\n",
    "        while sel['date_local'].nunique() < min_matches:\n",
    "            extra = by_temp_range(pool_wknd, T, d)\n",
    "            if extra is not None:\n",
    "                sel = pd.concat([sel, extra])\n",
    "            if sel['date_local'].nunique() >= min_matches:\n",
    "                break\n",
    "            d += 1\n",
    "            sel = by_temp_range(pool_h, T, d)\n",
    "    else:\n",
    "        sel = by_temp_range(pool, T, 0)\n",
    "        d = 0\n",
    "        while sel['date_local'].nunique() < min_matches:\n",
    "            d += 1\n",
    "            sel = by_temp_range(pool, T, d)\n",
    "\n",
    "    sel = sel[['date_local','hour','percent','daytype','temp_round']].drop_duplicates()\n",
    "    return sel\n",
    "\n",
    "def aggregate_profile(sample_df):\n",
    "    if sample_df.empty: return None\n",
    "    prof = sample_df.groupby('hour', as_index=False)['percent'].mean()\n",
    "    s = prof['percent'].sum()\n",
    "    if s>0: prof['percent'] = prof['percent']/s*100.0\n",
    "    return prof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a525681f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No forecast profiles generated. Check input data and sampling logic.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_30408\\1257831420.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     30\u001b[39m     print(\u001b[33m\"No forecast profiles generated. Check input data and sampling logic.\"\u001b[39m)\n\u001b[32m     31\u001b[39m     forecast_profiles = pd.DataFrame()\n\u001b[32m     32\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m forecast_meta = pd.DataFrame(debug_rows).sort_values(\u001b[33m'date'\u001b[39m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32mc:\\Users\\tarmo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7192\u001b[39m             )\n\u001b[32m   7193\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m len(by):\n\u001b[32m   7194\u001b[39m             \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[32m   7195\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m7196\u001b[39m             k = self._get_label_or_level_values(by[\u001b[32m0\u001b[39m], axis=axis)\n\u001b[32m   7197\u001b[39m \n\u001b[32m   7198\u001b[39m             \u001b[38;5;66;03m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[32m   7199\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32mc:\\Users\\tarmo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'date'"
     ]
    }
   ],
   "source": [
    "# --- Build 7-day forecast profiles ---\n",
    "profile_rows, debug_rows = [], []\n",
    "\n",
    "for _, row in forecast7.iterrows():\n",
    "    d, t, dtp = row['date'], row['temp_c'], row['daytype']\n",
    "    sel = select_sample_for_day(dtp, t, base, min_matches=MIN_MATCHES)\n",
    "    prof = aggregate_profile(sel)\n",
    "    if prof is None or prof.empty: \n",
    "        continue\n",
    "    for _, r in prof.iterrows():\n",
    "        profile_rows.append({'date': d, 'daytype': dtp, 'hour': int(r['hour']), 'percent': float(r['percent'])})\n",
    "    picked_days = sel[['date_local']].drop_duplicates().sort_values('date_local')\n",
    "    debug_rows.append({\n",
    "        'date': d,\n",
    "        'daytype': dtp,\n",
    "        'forecast_temp_c': float(t) if pd.notna(t) else None,\n",
    "        'temp_target_round': int(round(t)) if pd.notna(t) else None,\n",
    "        'temp_min_round': int(sel['temp_round'].min()) if not sel.empty else None,\n",
    "        'temp_max_round': int(sel['temp_round'].max()) if not sel.empty else None,\n",
    "        'n_days_used': int(picked_days.shape[0]),\n",
    "        'picked_dates': ','.join(picked_days['date_local'].astype(str).tolist())\n",
    "    })\n",
    "\n",
    "if profile_rows and 'date' in profile_rows[0] and 'hour' in profile_rows[0]:\n",
    "    forecast_profiles = pd.DataFrame(profile_rows).sort_values(['date','hour']).reset_index(drop=True)\n",
    "    forecast_profiles.to_csv(FORECAST_CSV, index=False)\n",
    "    print(\"Saved:\", FORECAST_CSV)\n",
    "    display(forecast_profiles.head(24))\n",
    "else:\n",
    "    print(\"No forecast profiles generated. Check input data and sampling logic.\")\n",
    "    forecast_profiles = pd.DataFrame()\n",
    "\n",
    "forecast_meta = pd.DataFrame(debug_rows).sort_values('date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DEBUG: Check forecast7 and base ---\n",
    "print(\"forecast7:\")\n",
    "print(forecast7)\n",
    "print(\"\\nbase sample:\")\n",
    "print(base.head(10))\n",
    "print(\"\\nbase daytypes:\", base['daytype'].unique())\n",
    "print(\"base temp_round range:\", base['temp_round'].min(), \"to\", base['temp_round'].max())\n",
    "\n",
    "# Try to select sample for the first forecast day\n",
    "if not forecast7.empty:\n",
    "    first = forecast7.iloc[0]\n",
    "    print(\"\\nFirst forecast day:\", first)\n",
    "    sel = select_sample_for_day(first['daytype'], first['temp_c'], base, min_matches=MIN_MATCHES)\n",
    "    print(\"Sample for first forecast day:\")\n",
    "    print(sel)\n",
    "    print(\"n_days_used:\", sel['date_local'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4b5dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Plots for quick visual check ---\n",
    "if not forecast_profiles.empty:\n",
    "    for d in sorted(forecast_profiles['date'].unique()):\n",
    "        sub = forecast_profiles[forecast_profiles['date']==d]\n",
    "        plt.figure(figsize=(9,4))\n",
    "        plt.plot(sub['hour'], sub['percent'], marker='o')\n",
    "        plt.title(f\"{d} – {sub['daytype'].iloc[0]}: 24h % profile (sum=100)\")\n",
    "        plt.xlabel(\"Hour\"); plt.ylabel(\"% of day\"); plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    # sample-temperature histogram for the first day\n",
    "    first = forecast_meta.iloc[0]\n",
    "    sel0 = select_sample_for_day(first['daytype'], first['forecast_temp_c'], base, min_matches=MIN_MATCHES)\n",
    "    if not sel0.empty:\n",
    "        tmp = sel0[['date_local','temp_round']].drop_duplicates()\n",
    "        plt.figure(figsize=(6,3.5))\n",
    "        tmp['temp_round'].hist(bins=range(int(tmp['temp_round'].min()-1), int(tmp['temp_round'].max()+2)))\n",
    "        plt.title(f\"Sample temp overview: {first['date']} ({first['daytype']}), target≈{first['temp_target_round']}°C\")\n",
    "        plt.xlabel(\"Temp (°C, rounded)\"); plt.ylabel(\"Days\"); plt.grid(True)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b902a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Optional CSV exports (commented) ---\n",
    "# (Uncomment if you want these for auditing)\n",
    "# profiles.to_csv(OUTPUT_DIR / \"historical_profiles_percent.csv\", index=False)\n",
    "# base.to_csv(OUTPUT_DIR / \"historical_daily_vectors.csv\", index=False)\n",
    "# forecast_meta.to_csv(OUTPUT_DIR / \"forecast_profiles_meta.csv\", index=False)\n",
    "print(\"Optional audit CSVs are commented out. Remove '#' to export them.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
